# ğŸ”’ AnÃ¡lisis de Clustering Forense - Ciberataques

Proyecto de anÃ¡lisis forense para determinar si los ciberataques registrados provienen de 2 o 3 atacantes distintos utilizando tÃ©cnicas de Machine Learning y clustering.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto utiliza PySpark MLlib para realizar un anÃ¡lisis exhaustivo de clustering sobre datos de ciberataques. El objetivo principal es identificar patrones de comportamiento que permitan determinar cuÃ¡ntos atacantes distintos estÃ¡n detrÃ¡s de los incidentes registrados.

### CaracterÃ­sticas Principales

- **AnÃ¡lisis Exploratorio de Datos (EDA)** completo con visualizaciones
- **Clustering con K-Means y GMM** (Gaussian Mixture Models)
- **ValidaciÃ³n con mÃºltiples mÃ©tricas**: Silhouette Score, ARI, BIC
- **IngenierÃ­a de caracterÃ­sticas** (ratios por minuto)
- **ReducciÃ³n dimensional con PCA** para visualizaciÃ³n
- **Dashboard interactivo** con Streamlit
- **VisualizaciÃ³n geogrÃ¡fica** de ataques

## ğŸ› ï¸ Requisitos

### Entorno de Desarrollo

- **Python**: 3.13.5
- **Gestor de paquetes**: Conda (recomendado)

### Dependencias Principales

```
- pyspark 4.0.1
- pandas
- numpy
- matplotlib
- seaborn
- plotly
- scikit-learn
- streamlit
- reportlab
```

## ğŸ“¦ InstalaciÃ³n

### 1. Clonar el Repositorio

```powershell
git clone https://github.com/Rodrimansidub14/ConsultingHacking.git
cd ConsultingHacking
```

### 2. Crear el Entorno Conda

```powershell
conda env create -f environment.yml
```

O crear manualmente:

```powershell
conda create -n py-3.13.5 python=3.13.5
conda activate py-3.13.5
```

### 3. Instalar Dependencias

Si creaste el entorno manualmente:

```powershell
conda install numpy pandas matplotlib seaborn reportlab
pip install pyspark plotly streamlit scikit-learn
```

## ğŸš€ EjecuciÃ³n del Proyecto

### AnÃ¡lisis en Jupyter Notebook

1. **Activar el entorno**:
   ```powershell
   conda activate py-3.13.5
   ```

2. **Abrir el notebook**:
   ```powershell
   jupyter notebook ConsultingNB.ipynb
   ```
   O simplemente abrir el archivo en VS Code.

3. **Ejecutar las celdas en orden** para:
   - Cargar y explorar los datos
   - Realizar feature engineering
   - Entrenar modelos de clustering
   - Generar visualizaciones
   - Exportar resultados a `data/hack_data_clustered.csv`

### Dashboard Interactivo

1. **Asegurarse de que el archivo de datos procesados existe**:
   - El notebook debe haber exportado `data/hack_data_clustered.csv`

2. **Activar el entorno** (si no estÃ¡ activo):
   ```powershell
   conda activate py-3.13.5
   ```

3. **Ejecutar el dashboard**:
   ```powershell
   streamlit run dashboard.py
   ```

4. **Acceder al dashboard**:
   - Abre tu navegador en: `http://localhost:8501`

### PÃ¡ginas del Dashboard

El dashboard incluye 5 secciones principales:

1. **ğŸ“Š Resumen Ejecutivo**
   - Objetivo y conclusiones del anÃ¡lisis
   - KPIs principales (Silhouette Score, ARI, Balance)
   - VisualizaciÃ³n PCA de separaciÃ³n de clusters

2. **ğŸ“ˆ AnÃ¡lisis Detallado**
   - Boxplots interactivos por mÃ©trica
   - GrÃ¡ficos de dispersiÃ³n con lÃ­neas de tendencia
   - ComparaciÃ³n de comportamiento entre clusters

3. **ğŸ‘¥ Perfiles de ClÃºsteres**
   - EstadÃ­sticas descriptivas por cluster
   - Histogramas y violin plots
   - ComparaciÃ³n de distribuciones

4. **ğŸŒ DistribuciÃ³n GeogrÃ¡fica**
   - Mapa interactivo de ataques por ubicaciÃ³n
   - TamaÃ±o de burbujas segÃºn frecuencia de ataques
   - Top 10 ubicaciones por cluster
   - MÃ©tricas geogrÃ¡ficas

5. **ğŸ”§ Detalles TÃ©cnicos**
   - Vista de datos procesados
   - Descarga de resultados en CSV
   - MetodologÃ­a completa

## ğŸ“Š Estructura del Proyecto

```
ConsultingHacking/
â”‚
â”œâ”€â”€ ConsultingNB.ipynb          # Notebook principal con anÃ¡lisis completo
â”œâ”€â”€ dashboard.py                # AplicaciÃ³n Streamlit
â”œâ”€â”€ environment.yml             # EspecificaciÃ³n del entorno conda
â”œâ”€â”€ README.md                   # Este archivo
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ hack_data.csv           # Datos originales
    â””â”€â”€ hack_data_clustered.csv # Datos procesados con clusters (generado)
```

## ğŸ“ˆ Resultados Principales

### ConclusiÃ³n del AnÃ¡lisis

âœ… **El anÃ¡lisis confirma la presencia de DOS (2) atacantes distintos**

### MÃ©tricas de ValidaciÃ³n

- **Silhouette Score**: 0.8176 (separaciÃ³n excelente)
- **Adjusted Rand Index (ARI)**: 1.000 (estabilidad perfecta)
- **Balance de Clusters**: 167/167 (perfectamente balanceado)
- **BIC (GMM)**: Favorece K=2 sobre K=3

### Diferencias entre Clusters

Los dos atacantes presentan comportamientos claramente diferenciados en:

- **DuraciÃ³n de sesiÃ³n**: Cluster 0 (sesiones cortas) vs Cluster 1 (sesiones largas)
- **Transferencia de datos**: Patrones de volumen opuestos
- **Velocidad de tecleo (WPM)**: Estilos de digitaciÃ³n distintos
- **Servidores comprometidos**: Estrategias de ataque diferentes
- **Uso de Kali Linux**: Preferencias de herramientas distintas

## ğŸ” MetodologÃ­a

1. **Carga y Limpieza de Datos**
   - Lectura con PySpark
   - NormalizaciÃ³n de nombres de columnas
   - Manejo de valores nulos

2. **Feature Engineering**
   - CreaciÃ³n de ratios por minuto:
     - `bytes_per_min`
     - `pages_per_min`
     - `servers_per_min`

3. **Clustering**
   - NormalizaciÃ³n con StandardScaler
   - K-Means con mÃ©todo del codo
   - GMM con validaciÃ³n BIC
   - Bootstrap para estabilidad

4. **ValidaciÃ³n**
   - Silhouette Score
   - Adjusted Rand Index
   - AnÃ¡lisis de balance de clusters

5. **VisualizaciÃ³n**
   - PCA para reducciÃ³n dimensional
   - Visualizaciones geogrÃ¡ficas
   - Dashboard interactivo

## ğŸ› SoluciÃ³n de Problemas

### Error: "ModuleNotFoundError: No module named 'plotly'"

```powershell
conda activate py-3.13.5
pip install plotly
```

### Error: "FileNotFoundError: data/hack_data_clustered.csv"

Ejecuta primero el notebook completo para generar el archivo de datos procesados.

### Error: Kernel restart en Jupyter

Reinstala las dependencias:
```powershell
conda activate py-3.13.5
pip install --force-reinstall pyspark
```

### Dashboard no se actualiza

DetÃ©n el servidor (Ctrl+C) y reinicia:
```powershell
streamlit run dashboard.py
```

## ğŸ“ Notas Importantes

- **PySpark en Windows**: El proyecto utiliza `.toPandas()` en lugar de operaciones RDD para evitar problemas de conexiÃ³n de workers en Windows con Python 3.13
- **Memoria**: PySpark puede requerir memoria considerable. Se recomienda al menos 8GB de RAM
- **Datos**: El archivo `hack_data.csv` debe estar en la carpeta `data/` antes de ejecutar el notebook

## ğŸ‘¨â€ğŸ’» Autor

**Rodrigo Mansilla**
- GitHub: [@Rodrimansidub14](https://github.com/Rodrimansidub14)

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico y de investigaciÃ³n.

---

**Ãšltima actualizaciÃ³n**: Noviembre 2, 2025

Para preguntas o problemas, abrir un issue en el repositorio de GitHub.
